{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Block: A modularized approach to test and tune multiple regression algorithms with minimal manual intervention!\n",
    "\n",
    "_Before you read: Not that this module is intended to facilitate quicker experimentation for the users with a moderate understanding of regression models and Python programming_\n",
    "\n",
    "## Introduction\n",
    "While working on one of my pet projects, I realised that sometimes it is better to test different model forms to determine the most suitable model which provides a good balance of accuracy, complexity and execution efficiency based on the problem at hand. Some of the softwares such as RapidMiner provide this functionality. However, using a software product for this purpose results in a black-box approach in terms of tuning the model and exploring some of the intricacies. Hence I decided to create a simple python script with just-enough modularization and parameterization to enable testing and tuning many of the widely used regression algorithms with minimal changes in the code.\n",
    "The summary of this notebook is as follows:\n",
    "\n",
    "#### Objective:\n",
    "To test, tune and compare various regression models with minimal manual intervention in Python.\n",
    "The models included in this module are:\n",
    "* Linear Regression\n",
    "* Ridge Regression\n",
    "* Lasso Regression\n",
    "* K Nearest Neighbors\n",
    "* Bayesian Ridge\n",
    "* Decision Tree Regression\n",
    "* Random Forest\n",
    "* Bagging (Using decision tree by default)\n",
    "* Gradient boosting\n",
    "* XGBoost\n",
    "* Support Vector Machines\n",
    "\n",
    "#### User Proficiency:\n",
    "The user should have an intuitive understanding of how each of these algorithms works along with a good understanding of how changing a particular hyper-parameter might impact the outcome. Basic understanding of python is required to be able to effectively utilize the code and further customize it based on requirements.\n",
    "\n",
    "#### Key Modifiable Inputs:\n",
    "Below are the key inputs (More details are provided for each input in the inline comments). These sections have been highlighted in the code with a note '__MAKE MODIFICATIONS HERE__':\n",
    "* Input dataset for regression analysis: In this example, I have used 'diabetes' dataset from pandas default datasets\n",
    "* Test data proportion: Between 0 to 1, default 0.3 (or 30%)\n",
    "* Normalization:  0 - No Normalization, 1 - Min-max scaling, 2 - Z-score scaling\n",
    "* List of model objects to test\n",
    "* Number of folds for grid-search (hyper-parameter tuning)\n",
    "* Scoring criteria to determine the best model (e.g. Mean squared error) - more details are provided in the code comments\n",
    "* Flag to see the level of detail on the terminal during model fit: 0 - No output, 1 - All details, 2 - Progress bar\n",
    "* Hyper-parameter library: A global dictionary in the code that provides set of hyper-parameters for each model form to tune on\n",
    "\n",
    "#### General Execution Steps:\n",
    "After taking these inputs, the following actions are performed for __each__ model form under consideration:\n",
    "* Forward feature selection\n",
    "* Normalization\n",
    "* Grid search for hyper-parameter tuning\n",
    "* Metric calculation for the best model\n",
    "\n",
    "#### Output\n",
    "A pandas dataframe 'results' is created which provides following metrics for each of the model forms you are testing\n",
    "* Model details with most optimum hyper-parameters\n",
    "* Train and test root mean squared errors\n",
    "* Train and test mean absolute percentage errors\n",
    "\n",
    "This table helps in comparing among various model forms while the train and test metrics can be a good indicator to spot overfitting.\n",
    "\n",
    "#### Important Note\n",
    "This module in no way deals with feature engineering and only performs feature selection based on the input data. It is highly important to perform effective feature engineering in order to improve results with any model. A user might observe one of the model forms giving better results than the other however overall performance of any model can be improved significantly with improvement in predictor variables.\n",
    "\n",
    "# Script\n",
    "\n",
    "#### Environment Setup\n",
    "This section imports all the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing general purpose libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import dfply as dp\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from sklearn import datasets\n",
    "\n",
    "# importing model selection and evaluation libraries\n",
    "\n",
    "# train-test-validation dataset creation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data normalization\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# feature selection\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from mlxtend.plotting import plot_sequential_feature_selection\n",
    "\n",
    "# hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# crossvalidation\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# accuracy testing\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "# Importing models\n",
    "\n",
    "# linear models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# non-parametric models\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Decision tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Support vectr machine\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# ensemble models\n",
    "\n",
    "# bagging\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "\n",
    "# tree based boosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# stacking\n",
    "from mlxtend.regressor import StackingRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modules for various tasks\n",
    "\n",
    "The first function creates the pipeline for normalization and grid search based on conditions specified by the user in the control panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(norm, model):\n",
    "    if norm == 1:\n",
    "        scale = StandardScaler()\n",
    "        pipe = Pipeline([('norm', scale), ('reg', model)])\n",
    "    elif norm == 2:\n",
    "        scale = MinMaxScaler()\n",
    "        pipe = Pipeline([('norm', scale), ('reg', model)])\n",
    "    else:\n",
    "        pipe = Pipeline([('reg', model)])\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function performs forward feature selection and returns the indices of best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(model, X_train, Y_train, selection,\n",
    "                    score_criteria, see_details, norm=0):\n",
    "    pipe = create_pipeline(norm, model)\n",
    "    sfs = SequentialFeatureSelector(pipe,\n",
    "                                    forward=selection,\n",
    "                                    k_features='best',\n",
    "                                    scoring=score_criteria,\n",
    "                                    verbose=see_details)\n",
    "    sfs = sfs.fit(X_train, Y_train)\n",
    "    return list(sfs.k_feature_idx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function performs grid search for provided parameter grid and returns best model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, param_grid, X_train, Y_train,\n",
    "              X, Y, score_criteria, folds,\n",
    "              see_details, norm=0):\n",
    "    pipe = create_pipeline(norm, model)\n",
    "    model_grid = GridSearchCV(pipe,\n",
    "                              param_grid,\n",
    "                              cv=folds,\n",
    "                              scoring=score_criteria,\n",
    "                              verbose=see_details)\n",
    "    model_grid.fit(X_train, Y_train)\n",
    "\n",
    "    return model_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last function calculates all the relevant metrics for the best hyper-parameter combination and returns a pandas series of these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_eval(model, X_train, Y_train, X_test, Y_test):\n",
    "    return pd.Series([model, mean_squared_error(Y_train, model.predict(X_train)),\n",
    "                      mean_squared_error(Y_test, model.predict(X_test)),\n",
    "                      (abs(model.predict(X_train) - Y_train) / Y_train).mean(),\n",
    "                      (abs(model.predict(X_test) - Y_test) / Y_test).mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Hyper-parameter Dictionary (__MAKE MODIFICATIONS HERE__)\n",
    "This is the global dictionary for various model parameters for all the models in this module. Some default set of values have been populated in the code for typical ranges based on the diabetes dataset. This dictionary contains some of the key hyper-parameters for each model and it is not exhaustive. Users are encouraged to visit scikit-learn documentation to get a list of all the parameters and add to the below dictionary according to their requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_DICT = {\n",
    "              LinearRegression: {'reg__copy_X': [True, False],\n",
    "                                 'reg__fit_intercept': [True, False],\n",
    "                                 'reg__n_jobs': [10, 20]},\n",
    "              Ridge: {'reg__alpha': [0.1, 1, 100],\n",
    "                      'reg__copy_X': [True, False],\n",
    "                      'reg__fit_intercept': [True, False],\n",
    "                      'reg__tol': [0.1, 1],\n",
    "                      'reg__solver': ['auto', 'svd', 'cholesky', 'lsqr',\n",
    "                                      'sparse_cg', 'sag', 'saga']},\n",
    "              Lasso: {'reg__alpha': [0.1, 1, 100],\n",
    "                      'reg__copy_X': [True, False],\n",
    "                      'reg__fit_intercept': [True, False],\n",
    "                      'reg__tol': [0.1, 1]},\n",
    "\n",
    "              KNeighborsRegressor: {'reg__n_neighbors': [5, 30, 100]},\n",
    "              BayesianRidge: {'reg__alpha_1': [10**-6, 10**-3],\n",
    "                              'reg__alpha_2': [10**-6, 10**-3],\n",
    "                              'reg__copy_X': [True, False],\n",
    "                              'reg__fit_intercept': [True, False],\n",
    "                              'reg__lambda_1': [10**-6, 10**-3],\n",
    "                              'reg__lambda_2': [10**-6, 10**-3],\n",
    "                              'reg__n_iter': [300, 500, 1000],\n",
    "                              'reg__tol': [0.001, 0.01, 0.1]},\n",
    "\n",
    "              DecisionTreeRegressor: {'reg__max_depth': [5, 10, 20],\n",
    "                                      'reg__max_features': [0.3, 0.7, 1.0],\n",
    "                                      'reg__max_leaf_nodes': [10, 50, 100],\n",
    "                                      'reg__splitter': ['best', 'random']},\n",
    "\n",
    "              BaggingRegressor: {\n",
    "                                 'reg__bootstrap': [True, False],\n",
    "                                 'reg__bootstrap_features': [True, False],\n",
    "                                 'reg__max_features': [0.3, 0.7, 1.0],\n",
    "                                 'reg__max_samples': [0.3, 0.7, 1.0],\n",
    "                                 'reg__n_estimators': [10, 50, 100]},\n",
    "              RandomForestRegressor: {'reg__bootstrap': [True, False],\n",
    "                                      'reg__max_depth': [5, 10, 20],\n",
    "                                      'reg__max_features': [0.3, 0.7, 1.0],\n",
    "                                      'reg__max_leaf_nodes': [10, 50, 100],\n",
    "                                      'reg__min_impurity_decrease': [0, 0.1, 0.2],\n",
    "                                      'reg__n_estimators': [10, 50, 100]},\n",
    "\n",
    "              SVR: {'reg__C': [10**-3, 1, 1000],\n",
    "                    'reg__kernel': ['linear', 'poly', 'rbf'],\n",
    "                    'reg__shrinking': [True, False]},\n",
    "\n",
    "              GradientBoostingRegressor: {'reg__learning_rate': [0.1, 0.2, 0.5],\n",
    "                                          'reg__loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "                                          'reg__max_depth': [10, 20, 50],\n",
    "                                          'reg__max_features': [0.5, 0.8, 1.0],\n",
    "                                          'reg__max_leaf_nodes': [10, 50, 100],\n",
    "                                          'reg__min_impurity_decrease': [0, 0.1, 0.2],\n",
    "                                          'reg__min_samples_leaf': [5, 10, 20],\n",
    "                                          'reg__min_samples_split': [5, 10, 20],\n",
    "                                          'reg__n_estimators': [10, 50, 100]},\n",
    "              XGBRegressor: {'reg__booster': ['gbtree', 'gblinear', 'dart'],\n",
    "                             'reg__learning_rate': [0.2, 0.5, 0.8],\n",
    "                             'reg__max_depth': [5, 10, 20],\n",
    "                             'reg__n_estimators': [10, 50, 100],\n",
    "                             'reg__reg_alpha': [0.1, 1, 10],\n",
    "                             'reg__reg_lambda': [0.1, 1, 10],\n",
    "                             'reg__subsample': [0.3, 0.5, 0.8]},\n",
    "\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Control Panel For Key Inputs (__MAKE MODIFICATIONS HERE__)\n",
    "The inputs to the modules can be changed here. This is the control panel for this script where all the variables mentioned in the introduction can be altered to test various scenarios. Please refer to the comments to understand the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# USER CONTROL PANEL, CHANGE THE VARIABLES, MODEL FORMS ETC. HERE\n",
    "\n",
    "# Read data here, define X (features) and Y (Target variable)\n",
    "data = datasets.load_diabetes()\n",
    "X = pd.DataFrame(data['data'])\n",
    "X.columns = data['feature_names']\n",
    "Y = data['target']\n",
    "\n",
    "# Specify size of test data (%)\n",
    "size = 0.3\n",
    "\n",
    "# Set random seed for sampling consistency\n",
    "random.seed(100)\n",
    "\n",
    "# Set type of normalization you want to perform\n",
    "# 0 - No Normalization, 1 - Min-max scaling, 2 - Zscore scaling\n",
    "norm = 0\n",
    "\n",
    "# Mention all model forms you want to run - Model Objects\n",
    "to_run = [LinearRegression,\n",
    "          Ridge,\n",
    "          Lasso,\n",
    "          KNeighborsRegressor,\n",
    "          DecisionTreeRegressor,\n",
    "          BaggingRegressor,\n",
    "          SVR,\n",
    "          XGBRegressor]\n",
    "\n",
    "# Specify number of crossvalidation folds\n",
    "folds = 5\n",
    "\n",
    "# Specify model selection criteria\n",
    "# Possible values are:\n",
    "# ‘explained_variance’\n",
    "# ‘neg_mean_absolute_error’\n",
    "# ‘neg_mean_squared_error’\n",
    "# ‘neg_mean_squared_log_error’\n",
    "# ‘neg_median_absolute_error’\n",
    "# ‘r2’\n",
    "score_criteria = 'neg_mean_absolute_error'\n",
    "\n",
    "# Specify details of terminal output you'd like to see\n",
    "# 0 - No output, 1 - All details, 2 - Progress bar\n",
    "# Outputs might vary based on individual functions\n",
    "see_details = 1\n",
    "\n",
    "# --------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Execution\n",
    "This section iteratively finds the best set of the hyperparameters for each of the model specified by the user, calculates the metrics and populates results table for further analysis/experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model execution part, resuts will be stored in the dataframe 'results'\n",
    "# Best model can be selected based on these criteria\n",
    "\n",
    "results = pd.DataFrame(columns=['ModelForm', 'TrainRMSE', 'TestRMSE',\n",
    "                                'TrainMAPE', 'TestMAPE'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=size)\n",
    "\n",
    "for model in to_run:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        best_feat = select_features(model(), X_train, Y_train, True,\n",
    "                                    score_criteria, see_details, norm)\n",
    "        model = run_model(model(), PARAM_DICT[model],\n",
    "                          X_train.iloc[:, best_feat],\n",
    "                          Y_train,\n",
    "                          X.iloc[:, best_feat], Y,\n",
    "                          score_criteria, folds, see_details, norm)\n",
    "        stats = get_model_eval(model, X_train.iloc[:, best_feat], Y_train,\n",
    "                               X_test.iloc[:, best_feat], Y_test)\n",
    "        stats.index = results.columns\n",
    "        results = results.append(stats, ignore_index=True)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "It can be observed from the results table that most basic linear regression model provides best and consistent performance among all the model forms tested in this scenario. This highlights the importance of feature engineering as well since we expect ensemble models to show better performance in general. On the other hand, XGB Regressor shows a sign of overfitting based on train and test metrics. All other models provide comparable performance. This indicates the need for testing a different range of hyper-parameters as well.\n",
    "I hope this module enables faster experimentation and provides an opportunity to build further customizations on top of it based on your needs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
